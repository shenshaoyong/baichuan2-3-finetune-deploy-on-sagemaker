{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc2611b",
   "metadata": {},
   "source": [
    "# Deploy Baichuan2 by using TGI 1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecb56f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU \"sagemaker>=2.163.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b59a0e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "import time\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5baf8fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "image_uri = get_huggingface_llm_image_uri(\n",
    "  backend=\"huggingface\", # or lmi\n",
    "  region=region\n",
    ")\n",
    "print(f\"image_uri: {image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01eb5cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_type : ml.g5.12xlarge\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# repo_id=\"baichuan-inc/Baichuan2-7B-Base\"\n",
    "\n",
    "# repo_id=\"baichuan-inc/Baichuan2-13B-Base\"\n",
    "\n",
    "# repo_id=\"baichuan-inc/Baichuan2-7B-Chat\"\n",
    "\n",
    "# repo_id=\"baichuan-inc/Baichuan2-7B-Chat-4bits\"\n",
    "\n",
    "repo_id=\"baichuan-inc/Baichuan2-13B-Chat\"\n",
    "\n",
    "# repo_id=\"baichuan-inc/Baichuan2-13B-Chat-4bits\"\n",
    "\n",
    "model_name = f\"{repo_id.split('/')[1]}-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "if(repo_id.endswith(\"-7B-Base\") or repo_id.endswith(\"-7B-Chat\") or repo_id.endswith(\"-Chat-4bits\")):\n",
    "    instance_type = \"ml.g5.2xlarge\"\n",
    "    number_of_partitions = 1\n",
    "elif(repo_id.endswith(\"-13B-Base\") or repo_id.endswith(\"-13B-Chat\")):\n",
    "    instance_type = \"ml.g5.12xlarge\"\n",
    "    number_of_partitions = 4\n",
    "else:\n",
    "    instance_type = \"ml.g5.2xlarge\"\n",
    "    number_of_partitions = 1\n",
    "print(f\"instance_type : {instance_type}\")\n",
    "\n",
    "hub = {\n",
    "    'HF_MODEL_ID':f'{repo_id}',\n",
    "    'HF_TASK':'text-generation',\n",
    "    'SM_NUM_GPUS':f\"{number_of_partitions}\",\n",
    "    'HF_MODEL_REVISION':'refs/pr/6',\n",
    "    'HF_API_TOKEN':'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',\n",
    "    'HF_TASK':'text-generation',\n",
    "    #'HF_MODEL_QUANTIZE':'bitsandbytes'\n",
    "}\n",
    "\n",
    "model = HuggingFaceModel(\n",
    "    name=model_name,\n",
    "    env=hub,\n",
    "    role=role,\n",
    "    image_uri=image_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d2038b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f873bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The diamondback terrapin was the first reptile to be released to science.\\nthe diamond-boat, but there was terrap post the first.\\nthe\\nthey, was the\\nScience\\n was was, was, was, they, was, and, was, was, was, was, was. was. The, was, was, was, was, was, was, was, was, was, was, was, was, was, was, was, was, was, was, was, was, was, was'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\n",
    "  \"inputs\": \"The diamondback terrapin was the first reptile to\",\n",
    "  \"parameters\": {\n",
    "    \"do_sample\": True,\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "    \"watermark\": True\n",
    "  }\n",
    "}\n",
    "\n",
    "predictor.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53820cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa7213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
